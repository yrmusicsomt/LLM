{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6wNIdCFy9Mi"
      },
      "source": [
        "# **Finetune Piper Vietnamese and export to ONNX **\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYt9-G5KztoJ"
      },
      "source": [
        "# **Install packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmRhSxjg_8oH"
      },
      "outputs": [],
      "source": [
        "# Setup Evironments\n",
        "!git clone -q https://github.com/rmcpantoja/piper\n",
        "%cd /content/piper/src/python\n",
        "!wget -q \"https://raw.githubusercontent.com/coqui-ai/TTS/dev/TTS/bin/resample.py\"\n",
        "!pip install -q cython>=0.29.0 piper-phonemize==1.1.0 librosa>=0.9.2 numpy>=1.19.0 onnxruntime==1.15.1 pytorch-lightning==1.7.0 torch==1.11.0\n",
        "!pip install -q torchtext==0.12.0 torchvision==0.12.0\n",
        "!pip install -q torchaudio==0.11.0 torchmetrics==0.11.4\n",
        "!pip install -q textgrid\n",
        "!bash build_monotonic_align.sh\n",
        "!apt-get install -q espeak-ng"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y93tn9ZMRR35"
      },
      "outputs": [],
      "source": [
        "# This is serious bug, update pip with 24.0.0 than pytorch-lightning can be installed !!!\n",
        "!pip install pip==24.0.0\n",
        "!pip install pytorch-lightning==1.7.0 onnxruntime piper_phonemize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZ3ZDVvG0AQA"
      },
      "source": [
        "# **Download datasets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZHLaZQ00dgZ"
      },
      "outputs": [],
      "source": [
        "!gdown 1-MqCJKtZojWmCESVEYVxMEzqa8oc3YfO\n",
        "!unzip thanhdata1111.zip -d wav/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AGpaCrF0IDB"
      },
      "source": [
        "# **Data preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coB6Fz9P0v1r"
      },
      "source": [
        "# **Resampling datasets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMFf65btAU4k"
      },
      "outputs": [],
      "source": [
        "# Convert to sample rate 22050 for high quality\n",
        "resample = True\n",
        "sample_rate = 22050\n",
        "if resample:\n",
        "  !python resample.py --input_dir \"wav\" --output_dir \"wavs_resampled\" --output_sr {sample_rate} --file_ext \"wav\"\n",
        "  !mv wavs_resampled wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dH_9CdWz7vY"
      },
      "outputs": [],
      "source": [
        "!cp wav/metadata.csv /content/piper/src/python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VWx3Tr80_CA"
      },
      "source": [
        "# **Preprocess text to Phonemes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wo9H2e9BHHH"
      },
      "outputs": [],
      "source": [
        "# Convert text to phonemize format\n",
        "dataset_format = \"ljspeech\"\n",
        "force_sp = \"--single-speaker\"\n",
        "!python -m piper_train.preprocess \\\n",
        "  --language vi \\\n",
        "  --input-dir /content/piper/src/python \\\n",
        "  --output-dir /content/piper/src/python \\\n",
        "  --dataset-format {dataset_format} \\\n",
        "  --sample-rate {sample_rate} \\\n",
        "  {force_sp}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMNXXiR71V9_"
      },
      "source": [
        "# **Download pretrained model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zG8HwnRPKGHZ"
      },
      "outputs": [],
      "source": [
        "# Download pretrain model from piper\n",
        "!wget https://huggingface.co/datasets/rhasspy/piper-checkpoints/resolve/main/vi/vi_VN/vais1000/medium/epoch%3D4769-step%3D919580.ckpt\n",
        "!wget https://huggingface.co/datasets/rhasspy/piper-checkpoints/raw/main/vi/vi_VN/vais1000/medium/config.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "je51ofn6KtQ6"
      },
      "outputs": [],
      "source": [
        "# Rename pretrain model for easy\n",
        "!mv epoch=4769-step=919580.ckpt pretrained_vi.ckpt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torchmetrics\n",
        "!pip install torchmetrics==0.11.4"
      ],
      "metadata": {
        "id": "PoHrOTRW1uKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROtQSpi11yq3"
      },
      "source": [
        "# **Training model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryKmwvEG12Wg"
      },
      "source": [
        "Setup params and ready for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zufXufuTETqT"
      },
      "outputs": [],
      "source": [
        "!python -m piper_train \\\n",
        "    --dataset-dir \"/content/piper/src/python/\" \\\n",
        "    --accelerator \"gpu\" \\\n",
        "    --devices 1 \\\n",
        "    --batch-size 30 \\\n",
        "    --validation-split 0.0 \\\n",
        "    --num-test-examples 2 \\\n",
        "    --quality \"medium\" \\\n",
        "    --checkpoint-epochs 5 \\\n",
        "    --log_every_n_steps 1 \\\n",
        "    --max_epochs 4799 \\\n",
        "    --resume_from_checkpoint \"/content/piper/src/python/pretrained_vi.ckpt\" \\\n",
        "    --precision 32\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2o0BH0WI2yIf"
      },
      "source": [
        "# **Export ONNX model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJVxtYYBZWzR"
      },
      "outputs": [],
      "source": [
        "# Export finetuned model to onnx\n",
        "!python3 -m piper_train.export_onnx \\\n",
        "    /content/piper/src/python/lightning_logs/version_0/checkpoints/epoch=4794-step=919680.ckpt \\\n",
        "    /content/finetuning_pretrained_vi.onnx\n",
        "\n",
        "!cp /content/piper/src/python/config.json \\\n",
        "   /content/finetuning_pretrained_vi.onnx.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vAV_krdS1Io"
      },
      "outputs": [],
      "source": [
        "# Export pretrained model to onnx\n",
        "    #/content/piper/src/python/lightning_logs/version_0/checkpoints/epoch=4799-step=919700.ckpt \\\n",
        "!python3 -m piper_train.export_onnx \\\n",
        "    /content/piper/src/python/pretrained_vi.ckpt \\\n",
        "    /content/pretrained_vi.onnx\n",
        "\n",
        "!cp /content/piper/src/python/config.json \\\n",
        "   /content/pretrained_vi.onnx.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zg0xVe_D28Rn"
      },
      "source": [
        "# **Test inference**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "We7lxJ_-IfSK"
      },
      "outputs": [],
      "source": [
        "!pip install piper-tts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PSUVMjChtaK"
      },
      "outputs": [],
      "source": [
        "!echo 'Trong tổng số khoảng 15 triệu cử tri người Mỹ gốc Á trong kỳ bầu cử tổng thống Mỹ năm 2024, số cử tri gốc Việt chỉ hơn 1 triệu người. Ở những kỳ bầu cử gần nhất, cử tri gốc Việt bỏ phiếu ủng hộ cho ứng viên nào, họ quan tâm đến những vấn đề gì và năm nay, họ có xu hướng ủng hộ ai nhiều hơn? Nghiên cứu sinh tiến sĩ Nguyễn Ngọc Yến My (Chuyên ngành Truyền thông và Công vụ - ĐH bang Louisiana, Mỹ) dẫn một số nguồn nghiên cứu và khảo sát để trả lời cho các câu hỏi này.' | \\\n",
        "  piper -m /content/finetuning_pretrained_vi.onnx --output_file /content/test1.wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaeWLrcTuAKc"
      },
      "outputs": [],
      "source": [
        "!echo 'Dự án đường sắt tốc độ cao Bắc Nam dự kiến dài 1.541 km, qua 20 tỉnh thành với tốc độ thiết kế 350 km/h, đi từ Hà Nội đến TP HCM hết 5,5 giờ, tiết kiệm thời gian 6 lần so với tàu hỏa thường.' | \\\n",
        "  piper -m /content/finetuning_pretrained_vi.onnx --output_file /content/test2.wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEZTj219q4ZJ"
      },
      "outputs": [],
      "source": [
        "# Quality of finetuned model\n",
        "from IPython.display import Audio\n",
        "Audio(\"/content/test2.wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4KfPAg1utcz"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "# Trigger the download\n",
        "files.download('/content/test2.wav')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fq9iA0OQ11w"
      },
      "outputs": [],
      "source": [
        "!echo 'Dự án đường sắt tốc độ cao Bắc Nam dự kiến dài 1.541 km, qua 20 tỉnh thành với tốc độ thiết kế 350 km/h, đi từ Hà Nội đến TP HCM hết 5,5 giờ, tiết kiệm thời gian 6 lần so với tàu hỏa thường.' | \\\n",
        "  piper -m /content/pretrained_vi.onnx --output_file /content/test_original.wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsFiFxV_-16q"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "# Step 1: Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the path in Google Drive where you want to save the file\n",
        "drive_path = '/content/drive/MyDrive/'\n",
        "\n",
        "# Step 3: Move the uploaded file to your Google Drive folder\n",
        "shutil.move('/content/piper/src/python/lightning_logs/version_0/checkpoints/epoch=4794-step=919680.ckpt', drive_path)\n",
        "\n",
        "print(f\"File successfully uploaded to: {drive_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}